# iTechSmart Suite v1.7.0 - AI Infrastructure Production Deployment
# Next Generation AI-Native IT Operations Platform

apiVersion: v1
kind: Namespace
metadata:
  name: itechsmart-ai
  labels:
    name: itechsmart-ai
    version: v1.7.0
    component: ai-infrastructure

---
# AI Inference Service - Real-time AI Processing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-inference-service
  namespace: itechsmart-ai
  labels:
    app: ai-inference-service
    version: v1.7.0
spec:
  replicas: 6
  selector:
    matchLabels:
      app: ai-inference-service
  template:
    metadata:
      labels:
        app: ai-inference-service
        version: v1.7.0
    spec:
      containers:
      - name: ai-inference
        image: itechsmart/ai-inference:v1.7.0
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        env:
        - name: MODEL_PATH
          value: "/models/predictive-maintenance-v1.7.0"
        - name: INFERENCE_TIMEOUT
          value: "50"  # 50ms target
        - name: BATCH_SIZE
          value: "32"
        - name: GPU_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 2000m
            memory: 4Gi
            nvidia.com/gpu: 1
          limits:
            cpu: 4000m
            memory: 8Gi
            nvidia.com/gpu: 1
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: model-storage
          mountPath: /models
        - name: cache-storage
          mountPath: /cache
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: ai-models-pvc
      - name: cache-storage
        persistentVolumeClaim:
          claimName: ai-cache-pvc

---
# AI Inference Service Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-inference-hpa
  namespace: itechsmart-ai
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-inference-service
  minReplicas: 6
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60

---
# Predictive Maintenance Engine
apiVersion: apps/v1
kind: Deployment
metadata:
  name: predictive-maintenance-engine
  namespace: itechsmart-ai
  labels:
    app: predictive-maintenance-engine
    version: v1.7.0
spec:
  replicas: 3
  selector:
    matchLabels:
      app: predictive-maintenance-engine
  template:
    metadata:
      labels:
        app: predictive-maintenance-engine
        version: v1.7.0
    spec:
      containers:
      - name: prediction-engine
        image: itechsmart/predictive-maintenance:v1.7.0
        ports:
        - containerPort: 8081
          name: http
        - containerPort: 9091
          name: metrics
        env:
        - name: PREDICTION_HORIZON
          value: "48"  # 48 hours advance prediction
        - name: ACCURACY_THRESHOLD
          value: "0.95"  # 95% accuracy target
        - name: DATA_RETENTION_DAYS
          value: "90"
        - name: MODEL_UPDATE_FREQUENCY
          value: "24h"  # Daily retraining
        resources:
          requests:
            cpu: 1500m
            memory: 6Gi
          limits:
            cpu: 3000m
            memory: 12Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
        volumeMounts:
        - name: prediction-data
          mountPath: /data
        - name: model-storage
          mountPath: /models
      volumes:
      - name: prediction-data
        persistentVolumeClaim:
          claimName: prediction-data-pvc
      - name: model-storage
        persistentVolumeClaim:
          claimName: ai-models-pvc

---
# ML Pipeline Orchestrator
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-pipeline-orchestrator
  namespace: itechsmart-ai
  labels:
    app: ml-pipeline-orchestrator
    version: v1.7.0
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ml-pipeline-orchestrator
  template:
    metadata:
      labels:
        app: ml-pipeline-orchestrator
        version: v1.7.0
    spec:
      containers:
      - name: orchestrator
        image: itechsmart/ml-pipeline:v1.7.0
        ports:
        - containerPort: 8082
          name: http
        - containerPort: 9092
          name: metrics
        env:
        - name: KUBEFLOW_ENDPOINT
          value: "http://kubeflow.kubeflow.svc.cluster.local"
        - name: TENSORBOARD_ENDPOINT
          value: "http://tensorboard.kubeflow.svc.cluster.local"
        - name: MLFLOW_ENDPOINT
          value: "http://mlflow.kubeflow.svc.cluster.local"
        - name: PIPELINE_TIMEOUT
          value: "3600"  # 1 hour
        resources:
          requests:
            cpu: 1000m
            memory: 4Gi
          limits:
            cpu: 2000m
            memory: 8Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8082
          initialDelaySeconds: 45
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8082
          initialDelaySeconds: 20
          periodSeconds: 10

---
# AI Model Training Service
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-model-training
  namespace: itechsmart-ai
  labels:
    app: ai-model-training
    version: v1.7.0
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-model-training
  template:
    metadata:
      labels:
        app: ai-model-training
        version: v1.7.0
    spec:
      containers:
      - name: training-service
        image: itechsmart/ai-training:v1.7.0
        ports:
        - containerPort: 8083
          name: http
        - containerPort: 9093
          name: metrics
        env:
        - name: TRAINING_SCHEDULE
          value: "0 2 * * *"  # Daily at 2 AM
        - name: MAX_TRAINING_TIME
          value: "7200"  # 2 hours max
        - name: MODEL_VALIDATION_SPLIT
          value: "0.2"  # 20% validation
        - name: PERFORMANCE_THRESHOLD
          value: "0.95"  # 95% accuracy required
        resources:
          requests:
            cpu: 3000m
            memory: 16Gi
            nvidia.com/gpu: 2
          limits:
            cpu: 6000m
            memory: 32Gi
            nvidia.com/gpu: 2
        volumeMounts:
        - name: training-data
          mountPath: /data
        - name: model-storage
          mountPath: /models
      volumes:
      - name: training-data
        persistentVolumeClaim:
          claimName: training-data-pvc
      - name: model-storage
        persistentVolumeClaim:
          claimName: ai-models-pvc

---
# AI Services - Load Balancer
apiVersion: v1
kind: Service
metadata:
  name: ai-inference-service
  namespace: itechsmart-ai
  labels:
    app: ai-inference-service
spec:
  selector:
    app: ai-inference-service
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: 9090
    protocol: TCP
  type: ClusterIP

---
# Predictive Maintenance Service
apiVersion: v1
kind: Service
metadata:
  name: predictive-maintenance-service
  namespace: itechsmart-ai
  labels:
    app: predictive-maintenance-engine
spec:
  selector:
    app: predictive-maintenance-engine
  ports:
  - name: http
    port: 80
    targetPort: 8081
    protocol: TCP
  - name: metrics
    port: 9091
    targetPort: 9091
    protocol: TCP
  type: ClusterIP

---
# ML Pipeline Service
apiVersion: v1
kind: Service
metadata:
  name: ml-pipeline-service
  namespace: itechsmart-ai
  labels:
    app: ml-pipeline-orchestrator
spec:
  selector:
    app: ml-pipeline-orchestrator
  ports:
  - name: http
    port: 80
    targetPort: 8082
    protocol: TCP
  - name: metrics
    port: 9092
    targetPort: 9092
    protocol: TCP
  type: ClusterIP

---
# AI Training Service
apiVersion: v1
kind: Service
metadata:
  name: ai-training-service
  namespace: itechsmart-ai
  labels:
    app: ai-model-training
spec:
  selector:
    app: ai-model-training
  ports:
  - name: http
    port: 80
    targetPort: 8083
    protocol: TCP
  - name: metrics
    port: 9093
    targetPort: 9093
    protocol: TCP
  type: ClusterIP

---
# AI Infrastructure Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ai-infrastructure-ingress
  namespace: itechsmart-ai
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "1000"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
spec:
  tls:
  - hosts:
    - ai.itechsmart.com
    secretName: ai-infrastructure-tls
  rules:
  - host: ai.itechsmart.com
    http:
      paths:
      - path: /inference
        pathType: Prefix
        backend:
          service:
            name: ai-inference-service
            port:
              number: 80
      - path: /predictive
        pathType: Prefix
        backend:
          service:
            name: predictive-maintenance-service
            port:
              number: 80
      - path: /pipeline
        pathType: Prefix
        backend:
          service:
            name: ml-pipeline-service
            port:
              number: 80
      - path: /training
        pathType: Prefix
        backend:
          service:
            name: ai-training-service
            port:
              number: 80

---
# Persistent Volume Claims for AI Infrastructure
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ai-models-pvc
  namespace: itechsmart-ai
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 500Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ai-cache-pvc
  namespace: itechsmart-ai
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prediction-data-pvc
  namespace: itechsmart-ai
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ssd
  resources:
    requests:
      storage: 1Ti

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: training-data-pvc
  namespace: itechsmart-ai
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: ssd
  resources:
    requests:
      storage: 2Ti